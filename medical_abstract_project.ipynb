{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1StfNvgsvao8rcH8RFROU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmblackwood/Medical_Abstract_Project/blob/main/medical_abstract_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ©º Medical Abstract Project ðŸ©º\n",
        "\n",
        "# Summary:\n",
        "Replicating the deep learning model behind the white paper PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts.\n",
        "Created a RNN, multi-__ clasifier model with ___.\n",
        "Libraries and Project used: PyTorch, SkimLit\n",
        "\n",
        "##1. Problem\n",
        "The number of Randomized Controlled Trials (RCTs) increases every year. Reading completely through even a small portion of them might not be the best use of a medical professional's time. I will create a model that will summarize the abstract, ___, ___ and ___ to help them skim through large bodies of information.\n",
        "\n",
        "##2. Data\n",
        "The dataset I'll be working with is provided in PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts at https://arxiv.org/abs/1710.06071\n",
        "\n",
        "##3. Machine Learning Model\n",
        "I will be replicating the deep learning model behind the paper, PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts. This paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
        "https://arxiv.org/abs/1710.06071\n",
        "\n",
        "In this paper, the authors state that they use the machine learning model described in Neural Networks for Joint Sentence Classification in Medical Paper Abstracts. I will be replicating this model.\n",
        "https://arxiv.org/abs/1612.05251\n",
        "\n",
        "From the white paper:\n",
        "\"The fourth baseline (bi-ANN) is an ANN consisting of three components: a token embedding\n",
        "layer (bi-LSTM), a sentence label prediction layer\n",
        "(bi-LSTM), and a label sequence optimization\n",
        "layer (CRF). The architecture is described in (Dernoncourt et al., 2016) and has been demonstrated\n",
        "to yield state-of-the-art results for sequential sentence classification.\"\n",
        "\n",
        "\n",
        "##4. Evaluation\n",
        "\n",
        "##5. Features"
      ],
      "metadata": {
        "id": "aQbBhSa1uDGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will perform the following steps:\n",
        "1. Download the text dataset (PubMed 200K RCT)\n",
        "2. Code a preprocessing function for my text data.\n",
        "3. Set up multiple modeling experiments with different levels of token embeddings.\n",
        "  - Make a baseline (TF-IDF classifier)\n",
        "  - Deep models with various combinations of: token embeddings, character embeddings, pretrained embeddings, positional embeddings.\n",
        "4. Build a multimodal model to take in different sources of data.\n",
        "5. Find the most wrong prediction examples ---- purpose?\n",
        "6. Make predictions on PubMed abstracts in the wild.\n"
      ],
      "metadata": {
        "id": "_vAUm3MyvE-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm Access to a GPU"
      ],
      "metadata": {
        "id": "nqhdh2oG4HEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA5SNPzBt_v4",
        "outputId": "42f34d62-360f-4953-a94f-1d6081dfd1cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-669a86d3-5a12-6760-bc7b-68861e6cf552)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Dataset\n",
        " Dataset can be found on the author's GitHub:\n",
        " https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "JsA5fqM94J2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "id": "ldbxP_kh4VJ6",
        "outputId": "af5831ac-2568-4238-c197-be005dee0ba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25 (from 1)\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 38.17 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at what files are in the dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "metadata": {
        "id": "yjtpPa3s4WKD",
        "outputId": "861fbf27-ab4a-452d-cee6-8c909d167a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… The dataset has a test and train set already. Note that the validation set is called \"dev.\""
      ],
      "metadata": {
        "id": "aRjoKcdz5sU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I'll begin experiments using the 20k dataset of with the numbers replaced by the @ sign.\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "3Mo2ZBNe4b0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "id": "d0y88ThK4ozz",
        "outputId": "0e543b78-5cbb-482c-fbbb-981e8951bd7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data\n",
        "I will write a function to read in all the lines of the target text file."
      ],
      "metadata": {
        "id": "soYcRdvl4rji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads the filename (text filename) and returns the lines of text as a list.\n",
        "\n",
        "  Args:\n",
        "    filename: target file path in the form of a string.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line.\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()\n"
      ],
      "metadata": {
        "id": "OazML2mf5NA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the training lines\n",
        "train_lines = get_lines(data_dir+\"train.txt\") # Read the lines with the training file.\n",
        "train_lines[:27]"
      ],
      "metadata": {
        "id": "z-zpSODW5Z07",
        "outputId": "42b90eb2-c247-4307-8954-2bb92d345956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… \\t means tab in the data.\n",
        "I need a function to separate labels from the text and make it easier for our model to take in."
      ],
      "metadata": {
        "id": "ccvFqi0I56Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "id": "Sm_7ls3w5lyb",
        "outputId": "66e9e8e8-c432-46c0-f837-d04acbb2b10a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the Data\n",
        "I have over 200,000 lines. Now I need to decide how I would like to format the data. I need to separate the results, conclusions etc. I'll write a function that creates a list of dictionaries to format the data. This will allow me to make functions later to take in the data structure and manipulate it in ways I want.\n",
        "\n",
        "I'll write a function to:\n",
        "\n",
        "1) Take the target file of abstract examples\n",
        "\n",
        "2) Read the lines in the target file\n",
        "\n",
        "3) For each line of the file:\n",
        "  - If the line begins with ###, mark it as an abstract ID and the beginning of a new abstract.\n",
        "    - Keep count of the number of lines in a sample.\n",
        "  - If the line begins with /n, mark it as the end of the abstract example.\n",
        "    - Keep count of the number of total lines in a sample.\n",
        "  - Record the text before the \\t as the label of the line.\n",
        "  - Record the text after the \\t as the text of the line.\n",
        "  \n",
        "4) Return all of the lines in the target text file as a list of dictionaries cotnaining these key/value pairs:\n",
        "    - \"line_number\" - the position of the line in the abstract (e.g., 3)\n",
        "    - \"target\" - the role of the line in the abstract (e.g., OBJECTIVE)\n",
        "    - \"text\" - the text of the line in the abstract\n",
        "    - \"total_lines\" - the total of the lines in an abstract sample (e.g., 14)\n",
        "\n",
        "5) Abstract IDs and new lines should be omitted from the returned, preprocessed data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ashyLyjniVZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of a single sample (a single line from the text)\n",
        "\n",
        "```\n",
        "[{\"line_number\":0,\n",
        "\"target\": \"OBJECTIVE\",\n",
        "\"text\": \"to investigate the efficacy of @ weeks of daily, low-dose...\",\n",
        "\"total_line\":11},\n",
        "...]\n",
        "```"
      ],
      "metadata": {
        "id": "DBTh3A-O5_BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_number(filename):\n",
        "  \"\"\"\n",
        "  returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in a filename, reads its contents adn sorts through each line, extracting the target label, text of the sentence, how many sentences are in the abstract and the sentence number.\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename)  # Get all lines from filename\n",
        "  abstract_lines = \"\"  # Create an empty abstract\n",
        "  abstract_samples = []  # Create an empty list of abstract\n",
        "\n",
        "  # Loop through each line in the target file.\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"):  # Check to see if this is an ID line (will give True/False output)\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\"  # Reset the abstract string if the line is an ID line. It will save everything up to the next ###, then resets to make room for the next batch.\n",
        "    elif line.isspace():  # Check if line is a new line. If it is, split the abstract into separate lines.\n",
        "      abstract_line_split = abstract_lines.splitlines()\n",
        "      # Iterate through each line in a single abstract and count them at the same time. \"abstract_line\" is the same as a sentence. Create empty dictionary per line.\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "          line_data = {}  # Create empty dictionary for each line.\n",
        "          target_text_split = abstract_line.split(\"\\t\")  # Split the target label from the text and put them into their own strings. Uses \"\\t\" as divider.\n",
        "          line_data[\"target\"] = target_text_split[0]  # Get the target label.\n",
        "          line_data[\"text\"] = target_text_split[1].lower()  # Get target text and lower it.\n",
        "          line_data[\"line_number\"] = abstract_line_number  # What number line is this line in the abstract?\n",
        "          line_data[\"total_lines\"] = len(abstract_line_split) - 1   # How many total ines are there in the target abstract. The -1 starts us at zero.\n",
        "          abstract_samples.append(line_data)  # Add line data to abstract sample list.\n",
        "    # If it's not a new line and not an ID line (start with ###), the line contains a labelled sentence and is also part of the same abstract.\n",
        "    else:\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "3dAYXaxyoWgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l9flzTuSwG4c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}